{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Low-Level Features vs Cross-Over Points\n",
    "\n",
    "Using machine learning models to predict cross-over bitrates  from low-level video features extracted from uncompressed videos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "import os, sys, warnings\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "sys.path.append(\"/home/krishna/Constructing-Per-Shot-Bitrate-Ladders-using-Visual-Information-Fidelity\")\n",
    "import bitrate_ladder_construction.BL_functions.dataset_evaluation_functions as dataset_evaluation_functions\n",
    "import defaults"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paths and Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "rq_points_dataset_path = defaults.rq_points_dataset_path\n",
    "features_path = defaults.llf_features_path\n",
    "\n",
    "# Features\n",
    "features_set = []\n",
    "for features_subset in [defaults.glcm_features, defaults.tc_features, defaults.si_features, defaults.ti_features, defaults.cti_features, defaults.cf_features, defaults.ci_features, defaults.dct_features]:\n",
    "\tfor f in features_subset:\n",
    "\t\tif \"max\" in f:\n",
    "\t\t\tcontinue\n",
    "\t\tfeatures_set.append(f)\n",
    "\t\n",
    "# Files\n",
    "train_video_filenames = defaults.Train_Video_Titles\n",
    "valid_video_filenames = defaults.Valid_Video_Titles\n",
    "test_video_filenames = defaults.Test_Video_Titles\n",
    "\n",
    "# Parameters\n",
    "Resolutions = defaults.resolutions\n",
    "CRFs = defaults.CRFs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-Over Bitrate-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of training dataset =  (70, 93) (70, 1)\n",
      "Dimensions of validation dataset =  (10, 93) (10, 1)\n",
      "Dimensions of test dataset =  (30, 93) (30, 1)\n"
     ]
    }
   ],
   "source": [
    "# Training, Validation and Test Datasets\n",
    "X_train_1, y_train_1 = dataset_evaluation_functions.LowLevelFeatures_CrossOverBitrates_Dataset(\n",
    "\tcodec=\"libx265\",\n",
    "\tpreset=\"medium\",\n",
    "\tquality_metric=\"vmaf\",\n",
    "\tfeatures_names=features_set,\n",
    "\tvideo_filenames=train_video_filenames,\n",
    "\ttemporal_low_level_features=False,\n",
    "\tResolutions_Considered=Resolutions,\n",
    "\tCRFs_Considered=CRFs,\n",
    "\tbitrates_Considered=None,\n",
    "\tQPs_Considered=None,\n",
    "\thigh_res=(3840,2160),\n",
    "\tlow_res=(2560,1440)\n",
    ")\n",
    "X_valid_1, y_valid_1 = dataset_evaluation_functions.LowLevelFeatures_CrossOverBitrates_Dataset(\n",
    "\tcodec=\"libx265\",\n",
    "\tpreset=\"medium\",\n",
    "\tquality_metric=\"vmaf\",\n",
    "\tfeatures_names=features_set,\n",
    "\ttemporal_low_level_features=False,\n",
    "\tvideo_filenames=valid_video_filenames,\n",
    "\tResolutions_Considered=Resolutions,\n",
    "\tCRFs_Considered=CRFs,\n",
    "\tbitrates_Considered=None,\n",
    "\tQPs_Considered=None,\n",
    "\thigh_res=(3840,2160),\n",
    "\tlow_res=(2560,1440)\n",
    ")\n",
    "X_test_1, y_test_1 = dataset_evaluation_functions.LowLevelFeatures_CrossOverBitrates_Dataset(\n",
    "\tcodec=\"libx265\",\n",
    "\tpreset=\"medium\",\n",
    "\tquality_metric=\"vmaf\",\n",
    "\tfeatures_names=features_set,\n",
    "\tvideo_filenames=test_video_filenames,\n",
    "\ttemporal_low_level_features=False,\n",
    "\tResolutions_Considered=Resolutions,\n",
    "\tCRFs_Considered=CRFs,\n",
    "\tbitrates_Considered=None,\n",
    "\tQPs_Considered=None,\n",
    "\thigh_res=(3840,2160),\n",
    "\tlow_res=(2560,1440)\n",
    ")\n",
    "\n",
    "# Assertions\n",
    "assert (X_train_1.shape[1] == X_valid_1.shape[1] == X_test_1.shape[1]) and (y_train_1.shape[1] == y_valid_1.shape[1] == y_test_1.shape[1]), \"No.of features do not match.\"\n",
    "print (\"Dimensions of training dataset = \", X_train_1.shape, y_train_1.shape)\n",
    "print (\"Dimensions of validation dataset = \", X_valid_1.shape, y_valid_1.shape)\n",
    "print (\"Dimensions of test dataset = \", X_test_1.shape, y_test_1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recursive Feature Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mean_GLCM_energy_mean', 'mean_GLCM_homogeneity_mean', 'mean_SI_mean', 'kurt_TI_std', 'skew_CF', 'skew_CI_V_mean', 'mean_E_Y', 'mean_h_Y', 'mean_h_V']\n"
     ]
    }
   ],
   "source": [
    "# Recursive Feature Elimination\n",
    "rfe_1 = RFE(estimator=RandomForestRegressor(n_estimators=1250, criterion=\"squared_error\", random_state=2, max_depth=12, max_features=\"log2\"), n_features_to_select=9)\n",
    "rfe_1.fit(X_train_1, y_train_1)\n",
    "indices = [i for i,v in enumerate(rfe_1.support_) if v]\n",
    "\n",
    "# Features Selected\n",
    "f = features_set\n",
    "print ([f[i] for i in indices])\n",
    "\n",
    "# Feature-Elimination on Inputs\n",
    "X_train_1 = X_train_1[...,indices]\n",
    "X_valid_1 = X_valid_1[...,indices]\n",
    "X_test_1 = X_test_1[...,indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Extra-Trees Regressor\n",
    "# print (\"Extra-Trees Regressor:\")\n",
    "# ETR_model_1 = ExtraTreesRegressor(n_estimators=1250, criterion=\"squared_error\", random_state=2, max_depth=12, max_features=\"log2\")\n",
    "# ETR_model_1.fit(X_train_1, y_train_1)\n",
    "\n",
    "# print (\"MSE =\", sklearn.metrics.mean_squared_error(ETR_model_1.predict(X_valid_1), y_valid_1))\n",
    "# print (\"PLCC =\", scipy.stats.pearsonr(ETR_model_1.predict(X_valid_1), y_valid_1)[0][0])\n",
    "# print (\"SRCC =\", scipy.stats.spearmanr(ETR_model_1.predict(X_valid_1), y_valid_1)[0])\n",
    "# print ()\n",
    "\n",
    "\n",
    "# # XG-Boost\n",
    "# print (\"XG-Boost Regressor:\")\n",
    "# XGB_model_1 = XGBRegressor(n_estimators=1250, learning_rate=0.0075, criterion=\"squared_error\", random_state=2, max_depth=12, max_features=\"log2\")\n",
    "# XGB_model_1.fit(X_train_1,y_train_1)\n",
    "\n",
    "# print (\"MSE =\", sklearn.metrics.mean_squared_error(XGB_model_1.predict(X_valid_1), y_valid_1))\n",
    "# print (\"PLCC =\", scipy.stats.pearsonr(XGB_model_1.predict(X_valid_1), y_valid_1)[0][0])\n",
    "# print (\"SRCC =\", scipy.stats.spearmanr(XGB_model_1.predict(X_valid_1), y_valid_1)[0])\n",
    "# print ()\n",
    "\n",
    "\n",
    "# # Random Forest\n",
    "# print (\"Random-Forest Regressor:\")\n",
    "# RF_model_1 = RandomForestRegressor(n_estimators=1250, criterion=\"squared_error\", random_state=2, max_depth=12, max_features=\"log2\")\n",
    "# RF_model_1.fit(X_train_1, y_train_1)\n",
    "\n",
    "# print (\"MSE =\", sklearn.metrics.mean_squared_error(RF_model_1.predict(X_valid_1), y_valid_1))\n",
    "# print (\"PLCC =\", scipy.stats.pearsonr(RF_model_1.predict(X_valid_1), y_valid_1)[0][0])\n",
    "# print (\"SRCC =\", scipy.stats.spearmanr(RF_model_1.predict(X_valid_1), y_valid_1)[0])\n",
    "# print ()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "\n",
      "MSE = 1.667\n",
      "PLCC = 0.186\n",
      "SRCC = 0.079\n",
      "\n",
      "Testing:\n",
      "\n",
      "MSE = 2.71\n",
      "PLCC = 0.305\n",
      "SRCC = 0.177\n"
     ]
    }
   ],
   "source": [
    "# Re-training best model on best features\n",
    "test_model_1 = ExtraTreesRegressor(n_estimators=1250, criterion=\"squared_error\", random_state=2, max_depth=12, max_features=\"log2\")\n",
    "test_model_1.fit(X_train_1, y_train_1)\n",
    "\n",
    "# Validation\n",
    "print (\"Validation:\\n\")\n",
    "print (\"MSE =\", np.round(sklearn.metrics.mean_squared_error(test_model_1.predict(X_valid_1), y_valid_1), decimals=3))\n",
    "print (\"PLCC =\", np.round(scipy.stats.pearsonr(test_model_1.predict(X_valid_1), y_valid_1)[0][0], decimals=3))\n",
    "print (\"SRCC =\", np.round(scipy.stats.spearmanr(test_model_1.predict(X_valid_1), y_valid_1)[0], decimals=3))\n",
    "print ()\n",
    "\n",
    "# Testing the model\n",
    "print (\"Testing:\\n\")\n",
    "print (\"MSE =\", np.round(sklearn.metrics.mean_squared_error(test_model_1.predict(X_test_1), y_test_1), decimals=3))\n",
    "print (\"PLCC =\", np.round(scipy.stats.pearsonr(test_model_1.predict(X_test_1), y_test_1)[0][0], decimals=3))\n",
    "print (\"SRCC =\", np.round(scipy.stats.spearmanr(test_model_1.predict(X_test_1), y_test_1)[0], decimals=3))\n",
    "\n",
    "# Saving the weights\n",
    "pickle.dump(test_model_1, open(\"/home/krishna/Constructing-Per-Shot-Bitrate-Ladders-using-Visual-Information-Fidelity/bitrate_ladder_construction/models/ML/CrossOver_Bitrates/low_level_features/model_cob_1.pkl\", \"wb\"))\n",
    "np.save(\"/home/krishna/Constructing-Per-Shot-Bitrate-Ladders-using-Visual-Information-Fidelity/bitrate_ladder_construction/models/ML/CrossOver_Bitrates/low_level_features/feature_indices_cob_1.npy\", indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-Over Bitrate-2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previous Cross-Over Bitrates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_COB_1 = test_model_1.predict(X_train_1).reshape(-1,1)\n",
    "valid_COB_1 = test_model_1.predict(X_valid_1).reshape(-1,1)\n",
    "test_COB_1 = test_model_1.predict(X_test_1).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of training dataset =  (70, 94) (70, 1)\n",
      "Dimensions of validation dataset =  (10, 94) (10, 1)\n",
      "Dimensions of test dataset =  (30, 94) (30, 1)\n"
     ]
    }
   ],
   "source": [
    "# Training, Validation and Test Datasets\n",
    "X_train_2, y_train_2 = dataset_evaluation_functions.LowLevelFeatures_CrossOverBitrates_Dataset(\n",
    "\tcodec=\"libx265\",\n",
    "\tpreset=\"medium\",\n",
    "\tquality_metric=\"vmaf\",\n",
    "\tfeatures_names=features_set,\n",
    "\tvideo_filenames=train_video_filenames,\n",
    "\ttemporal_low_level_features=False,\n",
    "\tResolutions_Considered=Resolutions,\n",
    "\tCRFs_Considered=CRFs,\n",
    "\tbitrates_Considered=None,\n",
    "\tQPs_Considered=None,\n",
    "\thigh_res=(2560,1440),\n",
    "\tlow_res=(1920,1080)\n",
    ")\n",
    "X_valid_2, y_valid_2 = dataset_evaluation_functions.LowLevelFeatures_CrossOverBitrates_Dataset(\n",
    "\tcodec=\"libx265\",\n",
    "\tpreset=\"medium\",\n",
    "\tquality_metric=\"vmaf\",\n",
    "\tfeatures_names=features_set,\n",
    "\tvideo_filenames=valid_video_filenames,\n",
    "\ttemporal_low_level_features=False,\n",
    "\tResolutions_Considered=Resolutions,\n",
    "\tCRFs_Considered=CRFs,\n",
    "\tbitrates_Considered=None,\n",
    "\tQPs_Considered=None,\n",
    "\thigh_res=(2560,1440),\n",
    "\tlow_res=(1920,1080)\n",
    ")\n",
    "X_test_2, y_test_2 = dataset_evaluation_functions.LowLevelFeatures_CrossOverBitrates_Dataset(\n",
    "\tcodec=\"libx265\",\n",
    "\tpreset=\"medium\",\n",
    "\tquality_metric=\"vmaf\",\n",
    "\tfeatures_names=features_set,\n",
    "\tvideo_filenames=test_video_filenames,\n",
    "\ttemporal_low_level_features=False,\n",
    "\tResolutions_Considered=Resolutions,\n",
    "\tCRFs_Considered=CRFs,\n",
    "\tbitrates_Considered=None,\n",
    "\tQPs_Considered=None,\n",
    "\thigh_res=(2560,1440),\n",
    "\tlow_res=(1920,1080)\n",
    ")\n",
    "\n",
    "# Concatenating Low-Level Features and Previous Cross-Over Bitrates\n",
    "X_train_2 = np.concatenate([X_train_2, train_COB_1], axis=1)\n",
    "X_valid_2 = np.concatenate([X_valid_2, valid_COB_1], axis=1)\n",
    "X_test_2 = np.concatenate([X_test_2, test_COB_1], axis=1)\n",
    "\n",
    "\n",
    "# Assertions\n",
    "assert (X_train_2.shape[1] == X_valid_2.shape[1] == X_test_2.shape[1]) and (y_train_2.shape[1] == y_valid_2.shape[1] == y_test_2.shape[1]), \"No.of features do not match.\"\n",
    "print (\"Dimensions of training dataset = \", X_train_2.shape, y_train_2.shape)\n",
    "print (\"Dimensions of validation dataset = \", X_valid_2.shape, y_valid_2.shape)\n",
    "print (\"Dimensions of test dataset = \", X_test_2.shape, y_test_2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recursive Feature Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mean_GLCM_contrast_std', 'mean_TC_mean', 'mean_TC_std', 'std_SI_mean', 'mean_TI_std', 'std_TI_mean', 'std_CTI_mean', 'mean_h_U', 'COB_1']\n"
     ]
    }
   ],
   "source": [
    "# Recursive Feature Elimination\n",
    "rfe_2 = RFE(estimator=RandomForestRegressor(n_estimators=1250, criterion=\"squared_error\", random_state=2, max_depth=12, max_features=\"log2\"), n_features_to_select=9)\n",
    "rfe_2.fit(X_train_2, y_train_2)\n",
    "indices = [i for i,v in enumerate(rfe_2.support_) if v]\n",
    "\n",
    "# Features Selected\n",
    "f = features_set + [\"COB_1\"]\n",
    "print ([f[i] for i in indices])\n",
    "\n",
    "# Feature-Elimination on Inputs\n",
    "X_train_2 = X_train_2[...,indices]\n",
    "X_valid_2 = X_valid_2[...,indices]\n",
    "X_test_2 = X_test_2[...,indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Extra-Trees Regressor\n",
    "# print (\"Extra-Trees Regressor:\")\n",
    "# ETR_model_2 = ExtraTreesRegressor(n_estimators=1250, criterion=\"squared_error\", random_state=2, max_depth=12, max_features=\"log2\")\n",
    "# ETR_model_2.fit(X_train_2, y_train_2)\n",
    "\n",
    "\n",
    "# print (\"MSE =\", sklearn.metrics.mean_squared_error(ETR_model_2.predict(X_valid_2), y_valid_2))\n",
    "# print (\"PLCC =\", scipy.stats.pearsonr(ETR_model_2.predict(X_valid_2), y_valid_2)[0][0])\n",
    "# print (\"SRCC =\", scipy.stats.spearmanr(ETR_model_2.predict(X_valid_2), y_valid_2)[0])\n",
    "# print ()\n",
    "\n",
    "\n",
    "# # XG-Boost\n",
    "# print (\"XG-Boost Regressor:\")\n",
    "# XGB_model_2 = XGBRegressor(n_estimators=1250, learning_rate=0.0075, criterion=\"squared_error\", random_state=2, max_depth=12, max_features=\"log2\")\n",
    "# XGB_model_2.fit(X_train_2,y_train_2)\n",
    "\n",
    "# print (\"MSE =\", sklearn.metrics.mean_squared_error(XGB_model_2.predict(X_valid_2), y_valid_2))\n",
    "# print (\"PLCC =\", scipy.stats.pearsonr(XGB_model_2.predict(X_valid_2), y_valid_2)[0][0])\n",
    "# print (\"SRCC =\", scipy.stats.spearmanr(XGB_model_2.predict(X_valid_2), y_valid_2)[0])\n",
    "# print ()\n",
    "\n",
    "\n",
    "# # Random Forest\n",
    "# print (\"Random-Forest Regressor:\")\n",
    "# RF_model_2 = RandomForestRegressor(n_estimators=1250, criterion=\"squared_error\", random_state=2, max_depth=12, max_features=\"log2\")\n",
    "# RF_model_2.fit(X_train_2, y_train_2)\n",
    "\n",
    "# print (\"MSE =\", sklearn.metrics.mean_squared_error(RF_model_2.predict(X_valid_2), y_valid_2))\n",
    "# print (\"PLCC =\", scipy.stats.pearsonr(RF_model_2.predict(X_valid_2), y_valid_2)[0][0])\n",
    "# print (\"SRCC =\", scipy.stats.spearmanr(RF_model_2.predict(X_valid_2), y_valid_2)[0])\n",
    "# print ()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "\n",
      "MSE = 1.811\n",
      "PLCC = 0.712\n",
      "SRCC = 0.673\n",
      "\n",
      "Testing:\n",
      "\n",
      "MSE = 2.092\n",
      "PLCC = 0.762\n",
      "SRCC = 0.816\n"
     ]
    }
   ],
   "source": [
    "# Re-training best model on best features\n",
    "test_model_2 = ExtraTreesRegressor(n_estimators=1250, criterion=\"squared_error\", random_state=2, max_depth=12, max_features=\"log2\")\n",
    "test_model_2.fit(X_train_2, y_train_2)\n",
    "\n",
    "# Validation\n",
    "print (\"Validation:\\n\")\n",
    "print (\"MSE =\", np.round(sklearn.metrics.mean_squared_error(test_model_2.predict(X_valid_2), y_valid_2), decimals=3))\n",
    "print (\"PLCC =\", np.round(scipy.stats.pearsonr(test_model_2.predict(X_valid_2), y_valid_2)[0][0], decimals=3))\n",
    "print (\"SRCC =\", np.round(scipy.stats.spearmanr(test_model_2.predict(X_valid_2), y_valid_2)[0], decimals=3))\n",
    "print ()\n",
    "\n",
    "# Testing the model\n",
    "print (\"Testing:\\n\")\n",
    "print (\"MSE =\", np.round(sklearn.metrics.mean_squared_error(test_model_2.predict(X_test_2), y_test_2), decimals=3))\n",
    "print (\"PLCC =\", np.round(scipy.stats.pearsonr(test_model_2.predict(X_test_2), y_test_2)[0][0], decimals=3))\n",
    "print (\"SRCC =\", np.round(scipy.stats.spearmanr(test_model_2.predict(X_test_2), y_test_2)[0], decimals=3))\n",
    "\n",
    "# Saving the weights\n",
    "pickle.dump(test_model_2, open(\"/home/krishna/Constructing-Per-Shot-Bitrate-Ladders-using-Visual-Information-Fidelity/bitrate_ladder_construction/models/ML/CrossOver_Bitrates/low_level_features/model_cob_2.pkl\", \"wb\"))\n",
    "np.save(\"/home/krishna/Constructing-Per-Shot-Bitrate-Ladders-using-Visual-Information-Fidelity/bitrate_ladder_construction/models/ML/CrossOver_Bitrates/low_level_features/feature_indices_cob_2.npy\", indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-Over Bitrate-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previous Cross-Over Bitrates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_COB_2 = test_model_2.predict(X_train_2).reshape(-1,1)\n",
    "valid_COB_2 = test_model_2.predict(X_valid_2).reshape(-1,1)\n",
    "test_COB_2 = test_model_2.predict(X_test_2).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of training dataset =  (70, 95) (70, 1)\n",
      "Dimensions of validation dataset =  (10, 95) (10, 1)\n",
      "Dimensions of test dataset =  (30, 95) (30, 1)\n"
     ]
    }
   ],
   "source": [
    "# Training, Validation and Test Datasets\n",
    "X_train_3, y_train_3 = dataset_evaluation_functions.LowLevelFeatures_CrossOverBitrates_Dataset(\n",
    "\tcodec=\"libx265\",\n",
    "\tpreset=\"medium\",\n",
    "\tquality_metric=\"vmaf\",\n",
    "\tfeatures_names=features_set,\n",
    "\tvideo_filenames=train_video_filenames,\n",
    "\ttemporal_low_level_features=False,\n",
    "\tResolutions_Considered=Resolutions,\n",
    "\tCRFs_Considered=CRFs,\n",
    "\tbitrates_Considered=None,\n",
    "\tQPs_Considered=None,\n",
    "\thigh_res=(1920,1080),\n",
    "\tlow_res=(1280,720)\n",
    ")\n",
    "X_valid_3, y_valid_3 = dataset_evaluation_functions.LowLevelFeatures_CrossOverBitrates_Dataset(\n",
    "\tcodec=\"libx265\",\n",
    "\tpreset=\"medium\",\n",
    "\tquality_metric=\"vmaf\",\n",
    "\tfeatures_names=features_set,\n",
    "\tvideo_filenames=valid_video_filenames,\n",
    "\ttemporal_low_level_features=False,\n",
    "\tResolutions_Considered=Resolutions,\n",
    "\tCRFs_Considered=CRFs,\n",
    "\tbitrates_Considered=None,\n",
    "\tQPs_Considered=None,\n",
    "\thigh_res=(1920,1080),\n",
    "\tlow_res=(1280,720)\n",
    ")\n",
    "X_test_3, y_test_3 = dataset_evaluation_functions.LowLevelFeatures_CrossOverBitrates_Dataset(\n",
    "\tcodec=\"libx265\",\n",
    "\tpreset=\"medium\",\n",
    "\tquality_metric=\"vmaf\",\n",
    "\tfeatures_names=features_set,\n",
    "\tvideo_filenames=test_video_filenames,\n",
    "\ttemporal_low_level_features=False,\n",
    "\tResolutions_Considered=Resolutions,\n",
    "\tCRFs_Considered=CRFs,\n",
    "\tbitrates_Considered=None,\n",
    "\tQPs_Considered=None,\n",
    "\thigh_res=(1920,1080),\n",
    "\tlow_res=(1280,720)\n",
    ")\n",
    "\n",
    "# Concatenating Low-Level Features and Previous Cross-Over Bitrates\n",
    "X_train_3 = np.concatenate([X_train_3, train_COB_1, train_COB_2], axis=1)\n",
    "X_valid_3 = np.concatenate([X_valid_3, valid_COB_1, valid_COB_2], axis=1)\n",
    "X_test_3 = np.concatenate([X_test_3, test_COB_1, test_COB_2], axis=1)\n",
    "\n",
    "\n",
    "# Assertions\n",
    "assert (X_train_3.shape[1] == X_valid_3.shape[1] == X_test_3.shape[1]) and (y_train_3.shape[1] == y_valid_3.shape[1] == y_test_3.shape[1]), \"No.of features do not match.\"\n",
    "print (\"Dimensions of training dataset = \", X_train_3.shape, y_train_3.shape)\n",
    "print (\"Dimensions of validation dataset = \", X_valid_3.shape, y_valid_3.shape)\n",
    "print (\"Dimensions of test dataset = \", X_test_3.shape, y_test_3.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recursive Feature Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mean_GLCM_homogeneity_std', 'mean_TC_mean', 'mean_TC_std', 'std_SI_mean', 'std_SI_std', 'mean_TI_std', 'std_CTI_mean', 'mean_h_Y', 'COB_2']\n"
     ]
    }
   ],
   "source": [
    "# Recursive Feature Elimination\n",
    "rfe_3 = RFE(estimator=RandomForestRegressor(n_estimators=1250, criterion=\"squared_error\", random_state=2, max_depth=12, max_features=\"log2\"), n_features_to_select=9)\n",
    "rfe_3.fit(X_train_3, y_train_3)\n",
    "indices = [i for i,v in enumerate(rfe_3.support_) if v]\n",
    "\n",
    "# Features Selected\n",
    "f = features_set + [\"COB_1\", \"COB_2\"]\n",
    "print ([f[i] for i in indices])\n",
    "\n",
    "# Feature-Elimination on Inputs\n",
    "X_train_3 = X_train_3[...,indices]\n",
    "X_valid_3 = X_valid_3[...,indices]\n",
    "X_test_3 = X_test_3[...,indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Extra-Trees Regressor\n",
    "# print (\"Extra-Trees Regressor:\")\n",
    "# ETR_model_3 = ExtraTreesRegressor(n_estimators=1250, criterion=\"squared_error\", random_state=2, max_depth=12, max_features=\"log2\")\n",
    "# ETR_model_3.fit(X_train_3, y_train_3)\n",
    "\n",
    "# print (\"MSE =\", sklearn.metrics.mean_squared_error(ETR_model_3.predict(X_valid_3), y_valid_3))\n",
    "# print (\"PLCC =\", scipy.stats.pearsonr(ETR_model_3.predict(X_valid_3), y_valid_3)[0][0])\n",
    "# print (\"SRCC =\", scipy.stats.spearmanr(ETR_model_3.predict(X_valid_3), y_valid_3)[0])\n",
    "# print ()\n",
    "\n",
    "\n",
    "# # XG-Boost\n",
    "# print (\"XG-Boost Regressor:\")\n",
    "# XGB_model_3 = XGBRegressor(n_estimators=1250, learning_rate=0.0075, criterion=\"squared_error\", random_state=2, max_depth=12, max_features=\"log2\")\n",
    "# XGB_model_3.fit(X_train_3,y_train_3)\n",
    "\n",
    "# print (\"MSE =\", sklearn.metrics.mean_squared_error(XGB_model_3.predict(X_valid_3), y_valid_3))\n",
    "# print (\"PLCC =\", scipy.stats.pearsonr(XGB_model_3.predict(X_valid_3), y_valid_3)[0][0])\n",
    "# print (\"SRCC =\", scipy.stats.spearmanr(XGB_model_3.predict(X_valid_3), y_valid_3)[0])\n",
    "# print ()\n",
    "\n",
    "\n",
    "# # Random Forest\n",
    "# print (\"Random-Forest Regressor:\")\n",
    "# RF_model_3 = RandomForestRegressor(n_estimators=1250, criterion=\"squared_error\", random_state=2, max_depth=12, max_features=\"log2\")\n",
    "# RF_model_3.fit(X_train_3, y_train_3)\n",
    "\n",
    "# print (\"MSE =\", sklearn.metrics.mean_squared_error(RF_model_3.predict(X_valid_3), y_valid_3))\n",
    "# print (\"PLCC =\", scipy.stats.pearsonr(RF_model_3.predict(X_valid_3), y_valid_3)[0][0])\n",
    "# print (\"SRCC =\", scipy.stats.spearmanr(RF_model_3.predict(X_valid_3), y_valid_3)[0])\n",
    "# print ()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "\n",
      "MSE = 2.353\n",
      "PLCC = 0.566\n",
      "SRCC = 0.733\n",
      "\n",
      "Testing:\n",
      "\n",
      "MSE = 1.615\n",
      "PLCC = 0.704\n",
      "SRCC = 0.747\n"
     ]
    }
   ],
   "source": [
    "# Re-training best model on best features\n",
    "test_model_3 = ExtraTreesRegressor(n_estimators=1250, criterion=\"squared_error\", random_state=2, max_depth=12, max_features=\"log2\")\n",
    "test_model_3.fit(X_train_3, y_train_3)\n",
    "\n",
    "# Validation\n",
    "print (\"Validation:\\n\")\n",
    "print (\"MSE =\", np.round(sklearn.metrics.mean_squared_error(test_model_3.predict(X_valid_3), y_valid_3), decimals=3))\n",
    "print (\"PLCC =\", np.round(scipy.stats.pearsonr(test_model_3.predict(X_valid_3), y_valid_3)[0][0], decimals=3))\n",
    "print (\"SRCC =\", np.round(scipy.stats.spearmanr(test_model_3.predict(X_valid_3), y_valid_3)[0], decimals=3))\n",
    "print ()\n",
    "\n",
    "# Testing the model\n",
    "print (\"Testing:\\n\")\n",
    "print (\"MSE =\", np.round(sklearn.metrics.mean_squared_error(test_model_3.predict(X_test_3), y_test_3), decimals=3))\n",
    "print (\"PLCC =\", np.round(scipy.stats.pearsonr(test_model_3.predict(X_test_3), y_test_3)[0][0], decimals=3))\n",
    "print (\"SRCC =\", np.round(scipy.stats.spearmanr(test_model_3.predict(X_test_3), y_test_3)[0], decimals=3))\n",
    "\n",
    "# Saving the weights\n",
    "pickle.dump(test_model_3, open(\"/home/krishna/Constructing-Per-Shot-Bitrate-Ladders-using-Visual-Information-Fidelity/bitrate_ladder_construction/models/ML/CrossOver_Bitrates/low_level_features/model_cob_3.pkl\", \"wb\"))\n",
    "np.save(\"/home/krishna/Constructing-Per-Shot-Bitrate-Ladders-using-Visual-Information-Fidelity/bitrate_ladder_construction/models/ML/CrossOver_Bitrates/low_level_features/feature_indices_cob_3.npy\", indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-Over Bitrate-4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previous Cross-Over Bitrates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_COB_3 = test_model_3.predict(X_train_3).reshape(-1,1)\n",
    "valid_COB_3 = test_model_3.predict(X_valid_3).reshape(-1,1)\n",
    "test_COB_3 = test_model_3.predict(X_test_3).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of training dataset =  (70, 96) (70, 1)\n",
      "Dimensions of validation dataset =  (10, 96) (10, 1)\n",
      "Dimensions of test dataset =  (30, 96) (30, 1)\n"
     ]
    }
   ],
   "source": [
    "# Training, Validation and Test Datasets\n",
    "X_train_4, y_train_4 = dataset_evaluation_functions.LowLevelFeatures_CrossOverBitrates_Dataset(\n",
    "\tcodec=\"libx265\",\n",
    "\tpreset=\"medium\",\n",
    "\tquality_metric=\"vmaf\",\n",
    "\tfeatures_names=features_set,\n",
    "\tvideo_filenames=train_video_filenames,\n",
    "\ttemporal_low_level_features=False,\n",
    "\tResolutions_Considered=Resolutions,\n",
    "\tCRFs_Considered=CRFs,\n",
    "\tbitrates_Considered=None,\n",
    "\tQPs_Considered=None,\n",
    "\thigh_res=(1280,720),\n",
    "\tlow_res=(960,540)\n",
    ")\n",
    "X_valid_4, y_valid_4 = dataset_evaluation_functions.LowLevelFeatures_CrossOverBitrates_Dataset(\n",
    "\tcodec=\"libx265\",\n",
    "\tpreset=\"medium\",\n",
    "\tquality_metric=\"vmaf\",\n",
    "\tfeatures_names=features_set,\n",
    "\tvideo_filenames=valid_video_filenames,\n",
    "\ttemporal_low_level_features=False,\n",
    "\tResolutions_Considered=Resolutions,\n",
    "\tCRFs_Considered=CRFs,\n",
    "\tbitrates_Considered=None,\n",
    "\tQPs_Considered=None,\n",
    "\thigh_res=(1280,720),\n",
    "\tlow_res=(960,540)\n",
    ")\n",
    "X_test_4, y_test_4 = dataset_evaluation_functions.LowLevelFeatures_CrossOverBitrates_Dataset(\n",
    "\tcodec=\"libx265\",\n",
    "\tpreset=\"medium\",\n",
    "\tquality_metric=\"vmaf\",\n",
    "\tfeatures_names=features_set,\n",
    "\tvideo_filenames=test_video_filenames,\n",
    "\ttemporal_low_level_features=False,\n",
    "\tResolutions_Considered=Resolutions,\n",
    "\tCRFs_Considered=CRFs,\n",
    "\tbitrates_Considered=None,\n",
    "\tQPs_Considered=None,\n",
    "\thigh_res=(1280,720),\n",
    "\tlow_res=(960,540)\n",
    ")\n",
    "\n",
    "# Concatenating Low-Level Features and Previous Cross-Over Bitrates\n",
    "X_train_4 = np.concatenate([X_train_4, train_COB_1, train_COB_2, train_COB_3], axis=1)\n",
    "X_valid_4 = np.concatenate([X_valid_4, valid_COB_1, valid_COB_2, valid_COB_3], axis=1)\n",
    "X_test_4 = np.concatenate([X_test_4, test_COB_1, test_COB_2, test_COB_3], axis=1)\n",
    "\n",
    "\n",
    "# Assertions\n",
    "assert (X_train_4.shape[1] == X_valid_4.shape[1] == X_test_4.shape[1]) and (y_train_4.shape[1] == y_valid_4.shape[1] == y_test_4.shape[1]), \"No.of features do not match.\"\n",
    "print (\"Dimensions of training dataset = \", X_train_4.shape, y_train_4.shape)\n",
    "print (\"Dimensions of validation dataset = \", X_valid_4.shape, y_valid_4.shape)\n",
    "print (\"Dimensions of test dataset = \", X_test_4.shape, y_test_4.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recursive Feature Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mean_GLCM_correlation_mean', 'std_SI_mean', 'std_SI_std', 'mean_TI_mean', 'mean_TI_std', 'std_CTI_mean', 'mean_h_Y', 'COB_2', 'COB_3']\n"
     ]
    }
   ],
   "source": [
    "# Recursive Feature Elimination\n",
    "rfe_4 = RFE(estimator=RandomForestRegressor(n_estimators=1250, criterion=\"squared_error\", random_state=2, max_depth=12, max_features=\"log2\"), n_features_to_select=9)\n",
    "rfe_4.fit(X_train_4, y_train_4)\n",
    "indices = [i for i,v in enumerate(rfe_4.support_) if v]\n",
    "\n",
    "# Features Selected\n",
    "f = features_set + [\"COB_1\", \"COB_2\", \"COB_3\"]\n",
    "print ([f[i] for i in indices])\n",
    "\n",
    "# Feature-Elimination on Inputs\n",
    "X_train_4 = X_train_4[...,indices]\n",
    "X_valid_4 = X_valid_4[...,indices]\n",
    "X_test_4 = X_test_4[...,indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Extra-Trees Regressor\n",
    "# print (\"Extra-Trees Regressor:\")\n",
    "# ETR_model_4 = ExtraTreesRegressor(n_estimators=1250, criterion=\"squared_error\", random_state=2, max_depth=12, max_features=\"log2\")\n",
    "# ETR_model_4.fit(X_train_4, y_train_4)\n",
    "\n",
    "# print (\"MSE =\", sklearn.metrics.mean_squared_error(ETR_model_4.predict(X_valid_4), y_valid_4))\n",
    "# print (\"PLCC =\", scipy.stats.pearsonr(ETR_model_4.predict(X_valid_4), y_valid_4)[0][0])\n",
    "# print (\"SRCC =\", scipy.stats.spearmanr(ETR_model_4.predict(X_valid_4), y_valid_4)[0])\n",
    "# print ()\n",
    "\n",
    "\n",
    "# # XG-Boost\n",
    "# print (\"XG-Boost Regressor:\")\n",
    "# XGB_model_4 = XGBRegressor(n_estimators=1250, learning_rate=0.0075, criterion=\"squared_error\", random_state=2, max_depth=12, max_features=\"log2\")\n",
    "# XGB_model_4.fit(X_train_4,y_train_4)\n",
    "\n",
    "# print (\"MSE =\", sklearn.metrics.mean_squared_error(XGB_model_4.predict(X_valid_4), y_valid_4))\n",
    "# print (\"PLCC =\", scipy.stats.pearsonr(XGB_model_4.predict(X_valid_4), y_valid_4)[0][0])\n",
    "# print (\"SRCC =\", scipy.stats.spearmanr(XGB_model_4.predict(X_valid_4), y_valid_4)[0])\n",
    "# print ()\n",
    "\n",
    "\n",
    "# # Random Forest\n",
    "# print (\"Random-Forest Regressor:\")\n",
    "# RF_model_4 = RandomForestRegressor(n_estimators=1250, criterion=\"squared_error\", random_state=2, max_depth=12, max_features=\"log2\")\n",
    "# RF_model_4.fit(X_train_4, y_train_4)\n",
    "\n",
    "# print (\"MSE =\", sklearn.metrics.mean_squared_error(RF_model_4.predict(X_valid_4), y_valid_4))\n",
    "# print (\"PLCC =\", scipy.stats.pearsonr(RF_model_4.predict(X_valid_4), y_valid_4)[0][0])\n",
    "# print (\"SRCC =\", scipy.stats.spearmanr(RF_model_4.predict(X_valid_4), y_valid_4)[0])\n",
    "# print ()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "\n",
      "MSE = 3.534\n",
      "PLCC = 0.504\n",
      "SRCC = 0.539\n",
      "\n",
      "Testing:\n",
      "\n",
      "MSE = 1.636\n",
      "PLCC = 0.625\n",
      "SRCC = 0.679\n"
     ]
    }
   ],
   "source": [
    "# Re-training best model on best features\n",
    "test_model_4 = ExtraTreesRegressor(n_estimators=1250, criterion=\"squared_error\", random_state=2, max_depth=12, max_features=\"log2\")\n",
    "test_model_4.fit(X_train_4, y_train_4)\n",
    "\n",
    "# Validation\n",
    "print (\"Validation:\\n\")\n",
    "print (\"MSE =\", np.round(sklearn.metrics.mean_squared_error(test_model_4.predict(X_valid_4), y_valid_4), decimals=3))\n",
    "print (\"PLCC =\", np.round(scipy.stats.pearsonr(test_model_4.predict(X_valid_4), y_valid_4)[0][0], decimals=3))\n",
    "print (\"SRCC =\", np.round(scipy.stats.spearmanr(test_model_4.predict(X_valid_4), y_valid_4)[0], decimals=3))\n",
    "print ()\n",
    "\n",
    "# Testing the model\n",
    "print (\"Testing:\\n\")\n",
    "print (\"MSE =\", np.round(sklearn.metrics.mean_squared_error(test_model_4.predict(X_test_4), y_test_4), decimals=3))\n",
    "print (\"PLCC =\", np.round(scipy.stats.pearsonr(test_model_4.predict(X_test_4), y_test_4)[0][0], decimals=3))\n",
    "print (\"SRCC =\", np.round(scipy.stats.spearmanr(test_model_4.predict(X_test_4), y_test_4)[0], decimals=3))\n",
    "\n",
    "# Saving the weights\n",
    "pickle.dump(test_model_4, open(\"/home/krishna/Constructing-Per-Shot-Bitrate-Ladders-using-Visual-Information-Fidelity/bitrate_ladder_construction/models/ML/CrossOver_Bitrates/low_level_features/model_cob_4.pkl\", \"wb\"))\n",
    "np.save(\"/home/krishna/Constructing-Per-Shot-Bitrate-Ladders-using-Visual-Information-Fidelity/bitrate_ladder_construction/models/ML/CrossOver_Bitrates/low_level_features/feature_indices_cob_4.npy\", indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-Over Bitrate-5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previous Cross-Over Bitrates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_COB_4 = test_model_4.predict(X_train_4).reshape(-1,1)\n",
    "valid_COB_4 = test_model_4.predict(X_valid_4).reshape(-1,1)\n",
    "test_COB_4 = test_model_4.predict(X_test_4).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of training dataset =  (70, 97) (70, 1)\n",
      "Dimensions of validation dataset =  (10, 97) (10, 1)\n",
      "Dimensions of test dataset =  (30, 97) (30, 1)\n"
     ]
    }
   ],
   "source": [
    "# Training, Validation and Test Datasets\n",
    "X_train_5, y_train_5 = dataset_evaluation_functions.LowLevelFeatures_CrossOverBitrates_Dataset(\n",
    "\tcodec=\"libx265\",\n",
    "\tpreset=\"medium\",\n",
    "\tquality_metric=\"vmaf\",\n",
    "\tfeatures_names=features_set,\n",
    "\tvideo_filenames=train_video_filenames,\n",
    "\ttemporal_low_level_features=False,\n",
    "\tResolutions_Considered=Resolutions,\n",
    "\tCRFs_Considered=CRFs,\n",
    "\tbitrates_Considered=None,\n",
    "\tQPs_Considered=None,\n",
    "\thigh_res=(960,540),\n",
    "\tlow_res=(768,432)\n",
    ")\n",
    "X_valid_5, y_valid_5 = dataset_evaluation_functions.LowLevelFeatures_CrossOverBitrates_Dataset(\n",
    "\tcodec=\"libx265\",\n",
    "\tpreset=\"medium\",\n",
    "\tquality_metric=\"vmaf\",\n",
    "\tfeatures_names=features_set,\n",
    "\tvideo_filenames=valid_video_filenames,\n",
    "\ttemporal_low_level_features=False,\n",
    "\tResolutions_Considered=Resolutions,\n",
    "\tCRFs_Considered=CRFs,\n",
    "\tbitrates_Considered=None,\n",
    "\tQPs_Considered=None,\n",
    "\thigh_res=(960,540),\n",
    "\tlow_res=(768,432)\n",
    ")\n",
    "X_test_5, y_test_5 = dataset_evaluation_functions.LowLevelFeatures_CrossOverBitrates_Dataset(\n",
    "\tcodec=\"libx265\",\n",
    "\tpreset=\"medium\",\n",
    "\tquality_metric=\"vmaf\",\n",
    "\tfeatures_names=features_set,\n",
    "\tvideo_filenames=test_video_filenames,\n",
    "\ttemporal_low_level_features=False,\n",
    "\tResolutions_Considered=Resolutions,\n",
    "\tCRFs_Considered=CRFs,\n",
    "\tbitrates_Considered=None,\n",
    "\tQPs_Considered=None,\n",
    "\thigh_res=(960,540),\n",
    "\tlow_res=(768,432)\n",
    ")\n",
    "\n",
    "# Concatenating Low-Level Features and Previous Cross-Over Bitrates\n",
    "X_train_5 = np.concatenate([X_train_5, train_COB_1, train_COB_2, train_COB_3, train_COB_4], axis=1)\n",
    "X_valid_5 = np.concatenate([X_valid_5, valid_COB_1, valid_COB_2, valid_COB_3, valid_COB_4], axis=1)\n",
    "X_test_5 = np.concatenate([X_test_5, test_COB_1, test_COB_2, test_COB_3, test_COB_4], axis=1)\n",
    "\n",
    "\n",
    "# Assertions\n",
    "assert (X_train_5.shape[1] == X_valid_5.shape[1] == X_test_5.shape[1]) and (y_train_5.shape[1] == y_valid_5.shape[1] == y_test_5.shape[1]), \"No.of features do not match.\"\n",
    "print (\"Dimensions of training dataset = \", X_train_5.shape, y_train_5.shape)\n",
    "print (\"Dimensions of validation dataset = \", X_valid_5.shape, y_valid_5.shape)\n",
    "print (\"Dimensions of test dataset = \", X_test_5.shape, y_test_5.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recursive Feature Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mean_GLCM_correlation_mean', 'mean_SI_mean', 'std_SI_mean', 'mean_TI_std', 'mean_E_Y', 'mean_h_Y', 'COB_2', 'COB_3', 'COB_4']\n"
     ]
    }
   ],
   "source": [
    "# Recursive Feature Elimination\n",
    "rfe_5 = RFE(estimator=RandomForestRegressor(n_estimators=1250, criterion=\"squared_error\", random_state=2, max_depth=12, max_features=\"log2\"), n_features_to_select=9)\n",
    "rfe_5.fit(X_train_5, y_train_5)\n",
    "indices = [i for i,v in enumerate(rfe_5.support_) if v]\n",
    "\n",
    "# Features Selected\n",
    "f = features_set + [\"COB_1\", \"COB_2\", \"COB_3\", \"COB_4\"]\n",
    "print ([f[i] for i in indices])\n",
    "\n",
    "# Feature-Elimination on Inputs\n",
    "X_train_5 = X_train_5[...,indices]\n",
    "X_valid_5 = X_valid_5[...,indices]\n",
    "X_test_5 = X_test_5[...,indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Extra-Trees Regressor\n",
    "# print (\"Extra-Trees Regressor:\")\n",
    "# ETR_model_5 = ExtraTreesRegressor(n_estimators=1250, criterion=\"squared_error\", random_state=2, max_depth=12, max_features=\"log2\")\n",
    "# ETR_model_5.fit(X_train_5, y_train_5)\n",
    "\n",
    "# print (\"MSE =\", sklearn.metrics.mean_squared_error(ETR_model_5.predict(X_valid_5), y_valid_5))\n",
    "# print (\"PLCC =\", scipy.stats.pearsonr(ETR_model_5.predict(X_valid_5), y_valid_5)[0][0])\n",
    "# print (\"SRCC =\", scipy.stats.spearmanr(ETR_model_5.predict(X_valid_5), y_valid_5)[0])\n",
    "# print ()\n",
    "\n",
    "\n",
    "# # XG-Boost\n",
    "# print (\"XG-Boost Regressor:\")\n",
    "# XGB_model_5 = XGBRegressor(n_estimators=1250, learning_rate=0.0075, criterion=\"squared_error\", random_state=2, max_depth=12, max_features=\"log2\")\n",
    "# XGB_model_5.fit(X_train_5,y_train_5)\n",
    "\n",
    "# print (\"MSE =\", sklearn.metrics.mean_squared_error(XGB_model_5.predict(X_valid_5), y_valid_5))\n",
    "# print (\"PLCC =\", scipy.stats.pearsonr(XGB_model_5.predict(X_valid_5), y_valid_5)[0][0])\n",
    "# print (\"SRCC =\", scipy.stats.spearmanr(XGB_model_5.predict(X_valid_5), y_valid_5)[0])\n",
    "# print ()\n",
    "\n",
    "\n",
    "# # Random Forest\n",
    "# print (\"Random-Forest Regressor:\")\n",
    "# RF_model_5 = RandomForestRegressor(n_estimators=1250, criterion=\"squared_error\", random_state=2, max_depth=12, max_features=\"log2\")\n",
    "# RF_model_5.fit(X_train_5, y_train_5)\n",
    "\n",
    "# print (\"MSE =\", sklearn.metrics.mean_squared_error(RF_model_5.predict(X_valid_5), y_valid_5))\n",
    "# print (\"PLCC =\", scipy.stats.pearsonr(RF_model_5.predict(X_valid_5), y_valid_5)[0][0])\n",
    "# print (\"SRCC =\", scipy.stats.spearmanr(RF_model_5.predict(X_valid_5), y_valid_5)[0])\n",
    "# print ()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "\n",
      "MSE = 0.948\n",
      "PLCC = 0.628\n",
      "SRCC = 0.697\n",
      "\n",
      "Testing:\n",
      "\n",
      "MSE = 0.789\n",
      "PLCC = 0.697\n",
      "SRCC = 0.689\n"
     ]
    }
   ],
   "source": [
    "# Re-training best model on best features\n",
    "test_model_5 = ExtraTreesRegressor(n_estimators=1250, criterion=\"squared_error\", random_state=2, max_depth=12, max_features=\"log2\")\n",
    "test_model_5.fit(X_train_5, y_train_5)\n",
    "\n",
    "# Validation\n",
    "print (\"Validation:\\n\")\n",
    "print (\"MSE =\", np.round(sklearn.metrics.mean_squared_error(test_model_5.predict(X_valid_5), y_valid_5), decimals=3))\n",
    "print (\"PLCC =\", np.round(scipy.stats.pearsonr(test_model_5.predict(X_valid_5), y_valid_5)[0][0], decimals=3))\n",
    "print (\"SRCC =\", np.round(scipy.stats.spearmanr(test_model_5.predict(X_valid_5), y_valid_5)[0], decimals=3))\n",
    "print ()\n",
    "\n",
    "# Testing the model\n",
    "print (\"Testing:\\n\")\n",
    "print (\"MSE =\", np.round(sklearn.metrics.mean_squared_error(test_model_5.predict(X_test_5), y_test_5), decimals=3))\n",
    "print (\"PLCC =\", np.round(scipy.stats.pearsonr(test_model_5.predict(X_test_5), y_test_5)[0][0], decimals=3))\n",
    "print (\"SRCC =\", np.round(scipy.stats.spearmanr(test_model_5.predict(X_test_5), y_test_5)[0], decimals=3))\n",
    "\n",
    "# Saving the weights\n",
    "pickle.dump(test_model_5, open(\"/home/krishna/Constructing-Per-Shot-Bitrate-Ladders-using-Visual-Information-Fidelity/bitrate_ladder_construction/models/ML/CrossOver_Bitrates/low_level_features/model_cob_5.pkl\", \"wb\"))\n",
    "np.save(\"/home/krishna/Constructing-Per-Shot-Bitrate-Ladders-using-Visual-Information-Fidelity/bitrate_ladder_construction/models/ML/CrossOver_Bitrates/low_level_features/feature_indices_cob_5.npy\", indices)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VirtualEnv1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
